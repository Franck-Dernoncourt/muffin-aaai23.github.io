<!DOCTYPE html>
<html lang="en">
<head>
<title>Multimodal AI for Financial Forecasting Workshop</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<link href="layout/styles/layout.css" rel="stylesheet" type="text/css" media="all">
</head>
<body id="top">
<div class="wrapper row1">
  <header id="header" class="hoc clear">
    <!-- ################################################################################################ -->
    <div id="logo" class="fl_left">
      <h1><a href="index.html">Muffin@AAAI 2023</a></h1>
    </div>
    <nav id="mainav" class="fl_right">
      <ul class="clear">
        <li><a href="index.html">Home</a></li>
        <li><a href="schedule.html">Schedule</a></li>
        <li><a href="talks.html">Invited Talks</a></li>
        <li class="active"><a href="cfp.html">CFP</a></li>
        <li><a href="index.html#important-date">Important Dates</a></li>
        <li><a href="index.html#organizer">Organizers</a></li>
      </ul>
    </nav>
    <!-- ################################################################################################ -->
  </header>
</div>
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<div class="wrapper bgded overlay" style="background-image:url('images/demo/backgrounds/milky-way.jpeg');">
  <div id="pageintro" class="hoc clear">
    <!-- ################################################################################################ -->
      <h3 class="heading">The AAAI-2023 Workshop on <br>Multimodal AI for Financial Forecasting</h3>
      <h4>Feb 13, 2023</h4>
      <h4>Location: Washington DC, USA</h4>
    <!-- ################################################################################################ -->
  </div>
</div>
<!-- ################################################################################################ -->
<div class="wrapper row3" style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">Introduction</h6>
        <p>
          Thanks to the development of the Internet and video services such as YouTube, Facebook, and Twitch,
          people can easily share their own videos with people across continents on a daily basis.
          Along with books, these videos have become a new source of knowledge.
          However, the quality of information in some of these videos is sometimes questionable
          and may contain unintentional or intentional misinformation, and political bias.
        </p>

        <p>Moreover, the COVID-19 pandemic has resulted in the widespread adoption of remote working,
           remote learning, and remote conferencing.
           These remote working environments demand many new applications for efficient video transcript understanding,
           such as meeting recording understanding, quality assurance in call centers, and automatic test scoring in educational testing.
           The recent advancements in methods and resources for speech recognition
           have also created more research opportunities around video transcript understanding.
        </p>
      </div>
    </section>
  </main>
</div>

<!-- ################################################################################################ -->
<div class="wrapper row3" style="background-color: lightgray;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">Topics</h6>
        <p>
          This workshop will hold a research track and a shared task track. The research track aims to explore recent advances and challenges of multimodal AI for finance. As this topic is an inherently multi-modal subject, researchers from artificial intelligence, computer vision, speech processing, natural language processing, data mining, statistics, optimization, and other fields are invited to submit papers on recent advances, resources, tools, and challenges on the broad theme of Multimodal AI for finance. The topics of the workshop include but are not limited to the following:
        </p>

        <ul>
          <li>Transformer models / Self-supervised / Transfer Learning on Financial Data</li>
          <li>Machine Learning for Finance</li>
          <li>Natural Language Processing and Speech Applications for Finance</li>
          <li>Conversational dialogue modeling for Financial Conference Calls</li>
          <li>Social media and User NLP for Finance</li>
          <li>Entity extraction and linking, Named-entity recognition, information extraction, relationship extraction, ontology learning in financial documents</li>
          <li>Financial Document Processing </li>
          <li>Multi-modal financial knowledge discovery</li>
          <li>Financial Event detection from Multimedia</li>
          <li>Visiual-linguistic learning for financial video analysis</li>
          <li>Video understanding (human behavior cognition, topic mining, facial expression detection, emotion detection, deception detection, gait and posture analysis, etc.)</li>
          <li>Data annotation, acquisition, augmentation, feature engineering, for financial/time-series analysis</li>
          <li>Bias analysis and mitigation in financial models and data</li>
          <li>Statistical Modeling for Time Series Forecasting</li>
          <li>Interpretability and explainability for financial AI models</li>
          <li>Privacy-preserving AI for finance</li>
        </ul>
      </div>
    </section>
  </main>
</div>

<!-- ################################################################################################ -->
<div class="wrapper row3" style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">Important Dates</h6>
        <ul>
          <li>Paper submission deadline: November 4, 2022</li>
          <li>Acceptance notification: November 18, 2022</li>
          <li>Camera-ready submission: December 25, 2022</li>
          <li><strong>Muffin workshop at AAAI 2023:</strong> Feb 13, 2022</li>
        </ul>
        <p>All deadlines are “anywhere on earth” (UTC-12)</p>
      </div>
    </section>
  </main>
</div>
<!-- ################################################################################################ -->
<div class="wrapper row3" style="background-color: lightgray;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">Submission</h6>
        <p>Authors are invited to submit their unpublished work that represents novel research.
           The papers should be written in English using the AAAI-23 author kit
           and follow the AAAI 2023 formatting guidelines.
           Authors can also submit the supplementary materials, including technical appendices,
           source codes, datasets, and multimedia appendices.
           All submissions, including the main paper and its supplementary materials, should be fully anonymized.
           For more information on formatting and anonymity guidelines, please refer to AAAI 2023 call for paper page.
        </p>

        <p>All papers will be double blind peer reviewed. Muffin workshop accepts both long papers and short papers:</p>
        <ul>
          <li>
            <p>
              Short Paper: Up to 4 pages of content including the references.
              Upon the acceptance, the authors are provided with 1 more page to address the reviewer comments.
            </p>
          </li>
          <li>
            <p>
              Long Paper: Up to 8 pages of content including the references.
              Upon the acceptance, the authors are provided with 1 more page to address the reviewer comments.
            </p>
          </li>
        </ul>

        <p>Two reviewers with the same technical expertise will review each paper.
           Authors of the accepted papers will present their work in either the Oral or Poster session.
           All accepted papers will appear on the workshop proceedings that will be published on <a
                    href="http://ceur-ws.org/">CEUR-WS</a>.
           The authors will keep the copyright of their papers that are published on <a
                    href="http://ceur-ws.org/">CEUR-WS</a>.
           The workshop proceedings will be indexed by <a href="https://dblp.org/">DBLP</a>.
        </p>
        <p>Paper must be submitted using <a href="https://muffin-aaai23.github.io/index.html">EasyChair (TBD)</a>.
           For information on System Paper submission for the share tasks, please refer to our <a
                    href="shared_task.html">shared tasks</a> page.</p>
        <p></p>

          </p>
      </div>
    </section>
  </main>
</div>


<div class="wrapper row3" style="background-color: midnightblue;">
  <main class="hoc container clear">
    <div class="clear">
      <p style="color: antiquewhite;">Contact us: vtu-2022@googlegroups.com</p>
    </div>
  </main>
</div>



<a id="backtotop" href="#top"><i class="fa fa-chevron-up"></i></a>
<!-- JAVASCRIPTS -->
<script src="layout/scripts/jquery.min.js"></script>
<script src="layout/scripts/jquery.backtotop.js"></script>
<script src="layout/scripts/jquery.mobilemenu.js"></script>
</body>
</html>
